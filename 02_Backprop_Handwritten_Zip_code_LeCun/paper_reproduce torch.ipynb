{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ef99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image as Image\n",
    "# Training model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e385131c",
   "metadata": {},
   "source": [
    "## 1. Data\n",
    "\n",
    "### 1.1 Load from HF\n",
    "[USPS](https://huggingface.co/datasets/flwrlabs/usps) is a digit dataset scanned from envelopes by the U.S. Postal Service containing a total of $9,298$ samples of handwritten digits:\n",
    "* $7,291$ digits are used for training\n",
    "* $2,007$ digits are used for testing\n",
    "* each image is $16$ x $16$ pixels grayscale (not binary)\n",
    "* the images are within $[0,255]$ range, but we will normalize it to $[-1,1]$\n",
    "* the images are centered\n",
    "* they show a broad range of font styles\n",
    "\n",
    "One important feature of these images is that both the training set and the testing set contain numerous examples that are ambiguous, unclassifiable, or even misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc478d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bytes': b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      6\n",
       "1  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      5\n",
       "2  {'bytes': b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      4\n",
       "3  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      7\n",
       "4  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "train_df = pd.read_parquet(\"hf://datasets/flwrlabs/usps/\" + splits[\"train\"])\n",
    "test_df = pd.read_parquet(\"hf://datasets/flwrlabs/usps/\" + splits[\"test\"])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd398aa",
   "metadata": {},
   "source": [
    "### 1.2 Convert bytes to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0060df5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAIN SET ===\n",
      "train_images shape: (7291, 1, 16, 16)\n",
      "train_image_0 shape: (16, 16)\n"
     ]
    }
   ],
   "source": [
    "def convert_image_bytes_to_int(img: dict) -> np.ndarray:\n",
    "    # Convert the image bytes to numpy arrays\n",
    "    image = Image.open(io.BytesIO(img['bytes']))\n",
    "    return np.array(image)\n",
    "\n",
    "def convert_image_df_to_numpy(image_df: pd.DataFrame) -> np.ndarray:\n",
    "    images = image_df['image'].apply(convert_image_bytes_to_int)\n",
    "    # Convert to numpy array (consider the shape of all images is the same - 16x16)\n",
    "    train_images = np.zeros((len(images), 1, 16, 16))\n",
    "    for i, image in enumerate(images):\n",
    "        train_images[i][0] = image\n",
    "    return train_images\n",
    "\n",
    "train_images = convert_image_df_to_numpy(train_df)\n",
    "\n",
    "print(f\"=== TRAIN SET ===\")\n",
    "print(f\"train_images shape: {train_images.shape}\")\n",
    "print(f\"train_image_0 shape: {train_images[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a403cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST SET ===\n",
      "test_images shape: (2007, 1, 16, 16)\n",
      "test_image_0 shape: (16, 16)\n"
     ]
    }
   ],
   "source": [
    "test_images = convert_image_df_to_numpy(test_df)\n",
    "print(f\"=== TEST SET ===\")\n",
    "print(f\"test_images shape: {test_images.shape}\")\n",
    "print(f\"test_image_0 shape: {test_images[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0c99a",
   "metadata": {},
   "source": [
    "## 2. Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff4f0c",
   "metadata": {},
   "source": [
    "### 2.1 Normalize data [-1, 1]\n",
    "\n",
    "In order to prevent exploding gradients and slower computation we will scale the data to smaller numbers. \n",
    "\n",
    "In the original paper the data was scaled to the range of $[-1,1]$. We will do the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "573f8efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data [-1, 1]. We first scale the data to the range of [0, 2] and then shift it to the range of [-1, 1].\n",
    "train_images = train_images / 127.5 - 1\n",
    "test_images = test_images / 127.5 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9f4418",
   "metadata": {},
   "source": [
    "### 2.2 One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5875b1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAIN SET ===\n",
      "train_labels.shape: (7291, 10)\n",
      "train_labels[0]: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "### Convert labels to one-hot encoding\n",
    "def convert_labels_to_one_hot(df: pd.DataFrame) -> np.ndarray:\n",
    "    labels = df['label'].values\n",
    "    labels = np.eye(10)[labels]\n",
    "    return labels\n",
    "\n",
    "train_labels = convert_labels_to_one_hot(train_df)\n",
    "# Transform each label from horizontal to vertical\n",
    "train_labels = train_labels.reshape(train_labels.shape[0], 10)\n",
    "print(f\"=== TRAIN SET ===\")\n",
    "print(f\"train_labels.shape: {train_labels.shape}\")\n",
    "print(f\"train_labels[0]: {train_labels[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bec5e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST SET ===\n",
      "test_labels.shape: (2007, 10)\n",
      "test_labels[0]: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "test_labels = convert_labels_to_one_hot(test_df)\n",
    "print(f\"=== TEST SET ===\")\n",
    "print(f\"test_labels.shape: {test_labels.shape}\")\n",
    "print(f\"test_labels[0]: {test_labels[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d17a0d",
   "metadata": {},
   "source": [
    "## 3. Neural Net Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b5254d",
   "metadata": {},
   "source": [
    "### 3.1 Random weights\n",
    "Weights are initialized with random values within $U[-2.4/F, 2.4/F]$ range, where $F$ is the fan-in (number of inputs, connected to a neuron or a layer). \n",
    "\n",
    "**Reasoning**: *\"tends to keep total inputs in operating range of sigmoid\"*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7602b15",
   "metadata": {},
   "source": [
    "### 3.2 Activation function - LiSHT\n",
    "Basically, this function computes linearly scaled hyperbolic tangent:\n",
    "\n",
    "$$\\text{lisht}(x) = x * \\text{tanh}(x)$$\n",
    "\n",
    "#### Why Tanh\n",
    "\n",
    "In this paper LeCun's team applied **scaled hyperbolic tangent** (i.e. tanh) function to the output of each layer in the neural net. So the question is why this function? Why not simple `sigmoid` which is basically the same function, but within the $[0,1]$ range (`tanh`'s range is $[-1, 1]$).\n",
    "\n",
    "The only reason I can come up with is that `tanh` has steeper gradients than sigmoid (due to the bigger range), which means faster learning. Of course, we can achieve faster learning with higher `learning rate`. However, latter would increase the risk of divergence.\n",
    "\n",
    "Read more [HERE >>>](https://stats.stackexchange.com/questions/330559/why-is-tanh-almost-always-better-than-sigmoid-as-an-activation-function) .\n",
    "\n",
    "LeCun himself wrote following text in another paper:\n",
    "* *Symmetric functions of that kind are believed to yield **faster convergence**, although the learning can be extremely slow if some weights are too small (LeCun 1987).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72d7b8",
   "metadata": {},
   "source": [
    "### 3.3 Cost function - MSE\n",
    "The output cost function was the mean squared error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c386d1",
   "metadata": {},
   "source": [
    "### 3.4 Stochastic gradient descent\n",
    "In this paper SGD is chosen over Batch GD with following argument:\n",
    "* *The weights were updated according to the so-called stochastic gradient or \"on-line\" procedure (updating after each presentation of a single pattern) as opposed to the \"true\" gradient procedure (averaging over the whole training set before updating the weights). From empirical study (supported by theoretical arguments), the stochastic gradient was found to converge much faster than the true gradient, especially on large, redundant data bases. It also finds solutions that are\n",
    "more robust.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87669b50",
   "metadata": {},
   "source": [
    "<center><img src=\"img/lecun_zip_code_nn.png\" alt=\"Neural Network Architecture\" width=\"921\" height=\"468\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 1.</b> 1989 LeCun ConvNet per description in the paper</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57ced681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\" 1989 LeCun ConvNet per description in the paper \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # initialization as described in the paper to my best ability, but it doesn't look right...\n",
    "        winit = lambda fan_in, *shape: (torch.rand(*shape) - 0.5) * 2 * 2.4 / fan_in**0.5\n",
    "        macs = 0 # keep track of MACs (multiply accumulates)\n",
    "        acts = 0 # keep track of number of activations\n",
    "\n",
    "        # H1 layer parameters and their initialization\n",
    "        self.H1w = nn.Parameter(winit(5*5*1, 12, 1, 5, 5))\n",
    "        self.H1b = nn.Parameter(torch.zeros(12, 8, 8)) # presumably init to zero for biases\n",
    "        assert self.H1w.nelement() + self.H1b.nelement() == 1068\n",
    "        macs += (5*5*1) * (8*8) * 12\n",
    "        acts += (8*8) * 12\n",
    "\n",
    "        # H2 layer parameters and their initialization\n",
    "        \"\"\"\n",
    "        H2 neurons all connect to only 8 of the 12 input planes, with an unspecified pattern\n",
    "        I am going to assume the most sensible block pattern where 4 planes at a time connect\n",
    "        to differently overlapping groups of 8/12 input planes. We will implement this with 3\n",
    "        separate convolutions that we concatenate the results of.\n",
    "        \"\"\"\n",
    "        self.H2w = nn.Parameter(winit(5*5*8, 12, 8, 5, 5))\n",
    "        self.H2b = nn.Parameter(torch.zeros(12, 4, 4)) # presumably init to zero for biases\n",
    "        assert self.H2w.nelement() + self.H2b.nelement() == 2592\n",
    "        macs += (5*5*8) * (4*4) * 12\n",
    "        acts += (4*4) * 12\n",
    "\n",
    "        # H3 is a fully connected layer\n",
    "        self.H3w = nn.Parameter(winit(4*4*12, 4*4*12, 30))\n",
    "        self.H3b = nn.Parameter(torch.zeros(30))\n",
    "        assert self.H3w.nelement() + self.H3b.nelement() == 5790\n",
    "        macs += (4*4*12) * 30\n",
    "        acts += 30\n",
    "\n",
    "        # output layer is also fully connected layer\n",
    "        self.outw = nn.Parameter(winit(30, 30, 10))\n",
    "        self.outb = nn.Parameter(-torch.ones(10)) # 9/10 targets are -1, so makes sense to init slightly towards it\n",
    "        assert self.outw.nelement() + self.outb.nelement() == 310\n",
    "        macs += 30 * 10\n",
    "        acts += 10\n",
    "\n",
    "        self.macs = macs\n",
    "        self.acts = acts\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x has shape (1, 1, 16, 16)\n",
    "        x = F.pad(x, (2, 2, 2, 2), 'constant', -1.0) # pad by two using constant -1 for background\n",
    "        x = F.conv2d(x, self.H1w, stride=2) + self.H1b\n",
    "        x = torch.tanh(x)\n",
    "\n",
    "        # x is now shape (1, 12, 8, 8)\n",
    "        x = F.pad(x, (2, 2, 2, 2), 'constant', -1.0) # pad by two using constant -1 for background\n",
    "        slice1 = F.conv2d(x[:, 0:8], self.H2w[0:4], stride=2) # first 4 planes look at first 8 input planes\n",
    "        slice2 = F.conv2d(x[:, 4:12], self.H2w[4:8], stride=2) # next 4 planes look at last 8 input planes\n",
    "        slice3 = F.conv2d(torch.cat((x[:, 0:4], x[:, 8:12]), dim=1), self.H2w[8:12], stride=2) # last 4 planes are cross\n",
    "        x = torch.cat((slice1, slice2, slice3), dim=1) + self.H2b\n",
    "        x = torch.tanh(x)\n",
    "\n",
    "        # x is now shape (1, 12, 4, 4)\n",
    "        x = x.flatten(start_dim=1) # (1, 12*4*4)\n",
    "        x = x @ self.H3w + self.H3b\n",
    "        x = torch.tanh(x)\n",
    "\n",
    "        # x is now shape (1, 30)\n",
    "        x = x @ self.outw + self.outb\n",
    "        x = torch.tanh(x)\n",
    "\n",
    "         # x is finally shape (1, 10)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb70872b",
   "metadata": {},
   "source": [
    "## 4. Train\n",
    "\n",
    "* **NB**: In order to run following code you need CUDA enabled GPU. \n",
    "* **Running time**: Few minutes\n",
    "* **Results**: 95% accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55ef9330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model stats:\n",
      "# params:       9760\n",
      "# MACs:         63660\n",
      "# activations:  1000\n",
      "1\n",
      "eval: split train. loss 3.133231e-02. error 9.97%. misses: 726\n",
      "eval: split test . loss 3.674993e-02. error 14.50%. misses: 291\n",
      "2\n",
      "eval: split train. loss 2.061267e-02. error 5.95%. misses: 433\n",
      "eval: split test . loss 2.630060e-02. error 10.06%. misses: 202\n",
      "3\n",
      "eval: split train. loss 1.508845e-02. error 4.53%. misses: 329\n",
      "eval: split test . loss 2.083232e-02. error 8.87%. misses: 178\n",
      "4\n",
      "eval: split train. loss 1.185159e-02. error 3.81%. misses: 277\n",
      "eval: split test . loss 1.776443e-02. error 8.62%. misses: 173\n",
      "5\n",
      "eval: split train. loss 9.951142e-03. error 3.42%. misses: 248\n",
      "eval: split test . loss 1.597637e-02. error 8.27%. misses: 166\n",
      "6\n",
      "eval: split train. loss 8.715297e-03. error 3.11%. misses: 226\n",
      "eval: split test . loss 1.480246e-02. error 7.87%. misses: 158\n",
      "7\n",
      "eval: split train. loss 7.805854e-03. error 2.89%. misses: 211\n",
      "eval: split test . loss 1.393636e-02. error 7.32%. misses: 147\n",
      "8\n",
      "eval: split train. loss 7.093321e-03. error 2.76%. misses: 200\n",
      "eval: split test . loss 1.326590e-02. error 7.13%. misses: 143\n",
      "9\n",
      "eval: split train. loss 6.512322e-03. error 2.61%. misses: 189\n",
      "eval: split test . loss 1.273338e-02. error 6.98%. misses: 140\n",
      "10\n",
      "eval: split train. loss 6.023982e-03. error 2.37%. misses: 172\n",
      "eval: split test . loss 1.229922e-02. error 6.93%. misses: 139\n",
      "11\n",
      "eval: split train. loss 5.604612e-03. error 2.11%. misses: 153\n",
      "eval: split test . loss 1.193515e-02. error 6.83%. misses: 137\n",
      "12\n",
      "eval: split train. loss 5.239176e-03. error 1.99%. misses: 145\n",
      "eval: split test . loss 1.162499e-02. error 6.48%. misses: 130\n",
      "13\n",
      "eval: split train. loss 4.915762e-03. error 1.80%. misses: 130\n",
      "eval: split test . loss 1.135943e-02. error 6.43%. misses: 129\n",
      "14\n",
      "eval: split train. loss 4.625019e-03. error 1.69%. misses: 122\n",
      "eval: split test . loss 1.113129e-02. error 6.38%. misses: 128\n",
      "15\n",
      "eval: split train. loss 4.361287e-03. error 1.54%. misses: 111\n",
      "eval: split test . loss 1.093454e-02. error 6.38%. misses: 128\n",
      "16\n",
      "eval: split train. loss 4.121682e-03. error 1.49%. misses: 109\n",
      "eval: split test . loss 1.076383e-02. error 6.23%. misses: 125\n",
      "17\n",
      "eval: split train. loss 3.903938e-03. error 1.41%. misses: 102\n",
      "eval: split test . loss 1.061529e-02. error 6.28%. misses: 125\n",
      "18\n",
      "eval: split train. loss 3.705788e-03. error 1.36%. misses: 98\n",
      "eval: split test . loss 1.048479e-02. error 6.38%. misses: 128\n",
      "19\n",
      "eval: split train. loss 3.525274e-03. error 1.29%. misses: 94\n",
      "eval: split test . loss 1.036821e-02. error 6.33%. misses: 127\n",
      "20\n",
      "eval: split train. loss 3.360297e-03. error 1.23%. misses: 90\n",
      "eval: split test . loss 1.026363e-02. error 6.13%. misses: 123\n",
      "21\n",
      "eval: split train. loss 3.208809e-03. error 1.17%. misses: 84\n",
      "eval: split test . loss 1.017034e-02. error 6.08%. misses: 122\n",
      "22\n",
      "eval: split train. loss 3.068951e-03. error 1.15%. misses: 84\n",
      "eval: split test . loss 1.008752e-02. error 5.98%. misses: 120\n",
      "23\n",
      "eval: split train. loss 2.939045e-03. error 1.14%. misses: 82\n",
      "eval: split test . loss 1.001387e-02. error 5.73%. misses: 115\n"
     ]
    }
   ],
   "source": [
    "# init rng\n",
    "torch.manual_seed(1337)\n",
    "np.random.seed(1337)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "\n",
    "# init a model\n",
    "model = Net()\n",
    "model.to('cuda')\n",
    "print(\"model stats:\")\n",
    "print(\"# params:      \", sum(p.numel() for p in model.parameters())) # in paper total is 9,760\n",
    "print(\"# MACs:        \", model.macs)\n",
    "print(\"# activations: \", model.acts)\n",
    "\n",
    "# init data\n",
    "Xtr, Ytr = torch.from_numpy(train_images).to('cuda'), torch.from_numpy(train_labels).to('cuda')\n",
    "Xte, Yte = torch.from_numpy(test_images).to('cuda'), torch.from_numpy(test_labels).to('cuda')\n",
    "\n",
    "# init optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.03)\n",
    "\n",
    "def eval_split(split):\n",
    "    # eval the full train/test set, batched implementation for efficiency\n",
    "    model.eval()\n",
    "    X, Y = (Xtr, Ytr) if split == 'train' else (Xte, Yte)\n",
    "    Yhat = model(X)\n",
    "    loss = torch.mean((Y - Yhat)**2)\n",
    "    err = torch.mean((Y.argmax(dim=1) != Yhat.argmax(dim=1)).float())\n",
    "    print(f\"eval: split {split:5s}. loss {loss.item():e}. error {err.item()*100:.2f}%. misses: {int(err.item()*Y.size(0))}\")\n",
    "\n",
    "# train (23 iterations were used in the paper as well)\n",
    "for pass_num in range(23):\n",
    "\n",
    "    # perform one epoch of training\n",
    "    model.train()\n",
    "    for step_num in range(Xtr.size(0)):\n",
    "\n",
    "        # fetch a single example into a batch of 1\n",
    "        x, y = Xtr[[step_num]], Ytr[[step_num]]\n",
    "\n",
    "        # forward the model and the loss\n",
    "        yhat = model(x)\n",
    "        loss = torch.mean((y - yhat)**2)\n",
    "\n",
    "        # calculate the gradient and update the parameters\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # after epoch epoch evaluate the train and test error / metrics\n",
    "    print(pass_num + 1)\n",
    "    eval_split('train')\n",
    "    eval_split('test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
